{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RNNs.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jinKnypeisnJ"},"source":["# Задание 6: Рекуррентные нейронные сети (RNNs)\n","\n","Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"]},{"cell_type":"code","metadata":{"id":"P59NYU98GCb9","executionInfo":{"status":"ok","timestamp":1633355001137,"user_tz":-180,"elapsed":11,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["# !pip3 -qq install torch==0.4.1\n","# !pip3 -qq install bokeh==0.13.0\n","# !pip3 -qq install gensim==3.6.0\n","# !pip3 -qq install nltk\n","# !pip3 -qq install scikit-learn==0.20.2"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"8sVtGHmA9aBM","executionInfo":{"status":"ok","timestamp":1633355029720,"user_tz":-180,"elapsed":25121,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","\n","if torch.cuda.is_available():\n","    from torch.cuda import FloatTensor, LongTensor\n","else:\n","    from torch import FloatTensor, LongTensor\n","\n","np.random.seed(42)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-6CNKM3b4hT1"},"source":["# Рекуррентные нейронные сети (RNNs)"]},{"cell_type":"markdown","metadata":{"id":"O_XkoGNQUeGm"},"source":["## POS Tagging"]},{"cell_type":"markdown","metadata":{"id":"QFEtWrS_4rUs"},"source":["Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n","\n","![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n","\n","*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n","\n","Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n","\n","Мы порешаем сейчас POS Tagging для английского.\n","\n","Будем работать с таким набором тегов:\n","- ADJ - adjective (new, good, high, ...)\n","- ADP - adposition (on, of, at, ...)\n","- ADV - adverb (really, already, still, ...)\n","- CONJ - conjunction (and, or, but, ...)\n","- DET - determiner, article (the, a, some, ...)\n","- NOUN - noun (year, home, costs, ...)\n","- NUM - numeral (twenty-four, fourth, 1991, ...)\n","- PRT - particle (at, on, out, ...)\n","- PRON - pronoun (he, their, her, ...)\n","- VERB - verb (is, say, told, ...)\n","- . - punctuation marks (. , ;)\n","- X - other (ersatz, esprit, dunno, ...)"]},{"cell_type":"markdown","metadata":{"id":"EPIkKdFlHB-X"},"source":["Скачаем данные:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiA2dGmgF1rW","executionInfo":{"status":"ok","timestamp":1633355031668,"user_tz":-180,"elapsed":1962,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"a0ee1c9e-0def-41c7-b109-b5ae1fb67326"},"source":["import nltk\n","from sklearn.model_selection import train_test_split\n","\n","nltk.download('brown')\n","nltk.download('universal_tagset')\n","\n","data = nltk.corpus.brown.tagged_sents(tagset='universal')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"]}]},{"cell_type":"markdown","metadata":{"id":"d93g_swyJA_V"},"source":["Пример размеченного предложения:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QstS4NO0L97c","executionInfo":{"status":"ok","timestamp":1633355050556,"user_tz":-180,"elapsed":252,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"ab07226c-1de4-401c-8422-49f4fce4b1e6"},"source":["for word, tag in data[0]:\n","    print('{:15}\\t{}'.format(word, tag))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["The            \tDET\n","Fulton         \tNOUN\n","County         \tNOUN\n","Grand          \tADJ\n","Jury           \tNOUN\n","said           \tVERB\n","Friday         \tNOUN\n","an             \tDET\n","investigation  \tNOUN\n","of             \tADP\n","Atlanta's      \tNOUN\n","recent         \tADJ\n","primary        \tNOUN\n","election       \tNOUN\n","produced       \tVERB\n","``             \t.\n","no             \tDET\n","evidence       \tNOUN\n","''             \t.\n","that           \tADP\n","any            \tDET\n","irregularities \tNOUN\n","took           \tVERB\n","place          \tNOUN\n",".              \t.\n"]}]},{"cell_type":"markdown","metadata":{"id":"epdW8u_YXcAv"},"source":["Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n","\n","На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTai8Ta0lgwL","executionInfo":{"status":"ok","timestamp":1633355084442,"user_tz":-180,"elapsed":29709,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"74f51653-5775-49cb-da6e-e0eb45ebee8b"},"source":["train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n","train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n","\n","print('Words count in train set:', sum(len(sent) for sent in train_data))\n","print('Words count in val set:', sum(len(sent) for sent in val_data))\n","print('Words count in test set:', sum(len(sent) for sent in test_data))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Words count in train set: 739769\n","Words count in val set: 130954\n","Words count in test set: 290469\n"]}]},{"cell_type":"markdown","metadata":{"id":"eChdLNGtXyP0"},"source":["Построим маппинги из слов в индекс и из тега в индекс:\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCjwwDs6Zq9x","executionInfo":{"status":"ok","timestamp":1633355084816,"user_tz":-180,"elapsed":409,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"e9f83282-3de2-4558-d479-4c2a40122e3d"},"source":["words = {word for sample in train_data for word, tag in sample}\n","word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n","word2ind['<pad>'] = 0\n","\n","tags = {tag for sample in train_data for word, tag in sample}\n","tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n","tag2ind['<pad>'] = 0\n","\n","print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique words in train = 45441. Tags = {'ADJ', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'PRT', 'NOUN', 'NUM', 'X', 'DET', 'ADP'}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"URC1B2nvPGFt","executionInfo":{"status":"ok","timestamp":1633355097762,"user_tz":-180,"elapsed":683,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"ac1971b4-a7a8-420b-d2ee-8275fc6408a4"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from collections import Counter\n","\n","tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n","tag_distribution = [tag_distribution[tag] for tag in tags]\n","\n","plt.figure(figsize=(10, 5))\n","\n","bar_width = 0.35\n","plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n","plt.xticks(np.arange(len(tags)), tags)\n","    \n","plt.show()"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"gArQwbzWWkgi"},"source":["## Бейзлайн\n","\n","Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n","\n","![tag-context](https://www.nltk.org/images/tag-context.png)  \n","*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n","\n","На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n","\n","Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n","\n","Простейший вариант - униграммная модель, учитывающая только слово:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rWmSToIaeAo","executionInfo":{"status":"ok","timestamp":1633355107268,"user_tz":-180,"elapsed":4555,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"56fc4e94-c1f2-4faa-d22f-f05f6cd73864"},"source":["import nltk\n","\n","default_tagger = nltk.DefaultTagger('NN')\n","\n","unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n","print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of unigram tagger = 92.62%\n"]}]},{"cell_type":"markdown","metadata":{"id":"07Ymb_MkbWsF"},"source":["Добавим вероятности переходов:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjz_Rk0bbMyH","executionInfo":{"status":"ok","timestamp":1633355113074,"user_tz":-180,"elapsed":5816,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"901d50df-83e4-49bc-cac8-b61bbd0b9859"},"source":["bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n","print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of bigram tagger = 93.42%\n"]}]},{"cell_type":"markdown","metadata":{"id":"uWMw6QHvbaDd"},"source":["Обратите внимание, что `backoff` важен:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XCuxEBVbOY_","executionInfo":{"status":"ok","timestamp":1633355120682,"user_tz":-180,"elapsed":7618,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"1a5c6873-6be1-437b-d737-3067a6609935"},"source":["trigram_tagger = nltk.TrigramTagger(train_data, backoff=bigram_tagger)\n","print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of trigram tagger = 93.43%\n"]}]},{"cell_type":"markdown","metadata":{"id":"4t3xyYd__8d-"},"source":["## Увеличиваем контекст с рекуррентными сетями\n","\n","Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n","\n","Омонимия - основная причина, почему униграмная модель плоха:  \n","*“he cashed a check at the **bank**”*  \n","vs  \n","*“he sat on the **bank** of the river”*\n","\n","Поэтому нам очень полезно учитывать контекст при предсказании тега.\n","\n","Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n","\n","![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n","\n","Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."]},{"cell_type":"code","metadata":{"id":"RtRbz1SwgEqc","executionInfo":{"status":"ok","timestamp":1633355121705,"user_tz":-180,"elapsed":1032,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["def convert_data(data, word2ind, tag2ind):\n","    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n","    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n","    \n","    return X, y\n","\n","X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n","X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n","X_test, y_test = convert_data(test_data, word2ind, tag2ind)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"DhsTKZalfih6","executionInfo":{"status":"ok","timestamp":1633355121707,"user_tz":-180,"elapsed":12,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["def iterate_batches(data, batch_size):\n","    X, y = data\n","    n_samples = len(X)\n","\n","    indices = np.arange(n_samples)\n","    np.random.shuffle(indices)\n","    \n","    for start in range(0, n_samples, batch_size):\n","        end = min(start + batch_size, n_samples)\n","        \n","        batch_indices = indices[start:end]\n","        \n","        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n","        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        \n","        for batch_ind, sample_ind in enumerate(batch_indices):\n","            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n","            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n","            \n","        yield X_batch, y_batch"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4XsRII5kW5x","executionInfo":{"status":"ok","timestamp":1633355122045,"user_tz":-180,"elapsed":346,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"dd76c064-1e11-4e22-9317-8a4768a1c77c"},"source":["X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n","\n","X_batch.shape, y_batch.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((32, 4), (32, 4))"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"C5I9E9P6eFYv"},"source":["**Задание** Реализуйте `LSTMTagger`:"]},{"cell_type":"code","metadata":{"id":"WVEHju54d68T","executionInfo":{"status":"ok","timestamp":1633355122626,"user_tz":-180,"elapsed":15,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["class LSTMTagger(nn.Module):\n","    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n","        super().__init__()\n","        self.word_embeddings = nn.Embedding(vocab_size, word_emb_dim)\n","        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count)\n","        self.hidden2tag = nn.Linear(lstm_hidden_dim, tagset_size)\n","\n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence)\n","        lstm_out, _ = self.lstm(embeds)\n","        tag_space = self.hidden2tag(lstm_out)\n","        return tag_space"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q_HA8zyheYGH"},"source":["**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbrxsZ2mehWB","executionInfo":{"status":"ok","timestamp":1633355122963,"user_tz":-180,"elapsed":348,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"bcdced3f-d450-43a9-8eed-6f633e2a87c8"},"source":["model = LSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",")\n","\n","X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n","\n","logits = model(X_batch)\n","\n","print(torch.sum(torch.mul(torch.argmax(logits, dim=-1) == y_batch, X_batch != 0)).item(), torch.sum(X_batch != 0).item()) "],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["4 92\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMUyUm1hgpe3","executionInfo":{"status":"ok","timestamp":1633355124762,"user_tz":-180,"elapsed":290,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"7245918a-4489-4006-cb65-b555c933ccb1"},"source":["criterion = nn.CrossEntropyLoss(ignore_index=0)\n","print(criterion(torch.movedim(logits, 0, -1), y_batch.movedim(0, -1)))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2.5875, grad_fn=<NllLoss2DBackward>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"nSgV3NPUpcjH"},"source":["**Задание** Вставьте эти вычисление в функцию:"]},{"cell_type":"code","metadata":{"id":"FprPQ0gllo7b","executionInfo":{"status":"ok","timestamp":1633355128642,"user_tz":-180,"elapsed":8,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["import math\n","from tqdm import tqdm\n","\n","\n","def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n","    epoch_loss = 0\n","    correct_count = 0\n","    sum_count = 0\n","    \n","    is_train = not optimizer is None\n","    name = name or ''\n","    model.train(is_train)\n","    \n","    batches_count = math.ceil(len(data[0]) / batch_size)\n","    \n","    with torch.autograd.set_grad_enabled(is_train):\n","        with tqdm(total=batches_count) as progress_bar:\n","            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n","                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n","                logits = model(X_batch)\n","\n","                loss = criterion(torch.movedim(logits, 0, -1), y_batch.movedim(0, -1))\n","\n","                epoch_loss += loss.item()\n","\n","                if optimizer:\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","                \n","                cur_correct_count = torch.sum(torch.mul(torch.argmax(logits, dim=-1) == y_batch, y_batch != 0)).item()\n","                cur_sum_count = torch.sum(y_batch != 0).item()\n","\n","                correct_count += cur_correct_count\n","                sum_count += cur_sum_count\n","\n","                progress_bar.update()\n","                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n","                    name, loss.item(), cur_correct_count / cur_sum_count)\n","                )\n","                \n","            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n","                name, epoch_loss / batches_count, correct_count / sum_count)\n","            )\n","\n","    return epoch_loss / batches_count, correct_count / sum_count\n","\n","\n","def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n","        val_data=None, val_batch_size=None):\n","        \n","    if not val_data is None and val_batch_size is None:\n","        val_batch_size = batch_size\n","        \n","    for epoch in range(epochs_count):\n","        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n","        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n","        \n","        if not val_data is None:\n","            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pqfbeh1ltEYa","executionInfo":{"status":"ok","timestamp":1633355776051,"user_tz":-180,"elapsed":644693,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"94a6e676-adf9-4de0-b0b8-fcbd2aafeed2"},"source":["model = LSTMTagger(\n","    vocab_size=len(word2ind),\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n","optimizer = optim.Adam(model.parameters())\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["[1 / 50] Train: Loss = 0.68831, Accuracy = 78.31%: 100%|██████████| 572/572 [00:13<00:00, 43.64it/s]\n","[1 / 50]   Val: Loss = 0.35857, Accuracy = 88.31%: 100%|██████████| 13/13 [00:00<00:00, 37.18it/s]\n","[2 / 50] Train: Loss = 0.27386, Accuracy = 90.90%: 100%|██████████| 572/572 [00:12<00:00, 45.80it/s]\n","[2 / 50]   Val: Loss = 0.24127, Accuracy = 92.38%: 100%|██████████| 13/13 [00:00<00:00, 36.42it/s]\n","[3 / 50] Train: Loss = 0.18531, Accuracy = 93.86%: 100%|██████████| 572/572 [00:12<00:00, 46.00it/s]\n","[3 / 50]   Val: Loss = 0.19830, Accuracy = 93.87%: 100%|██████████| 13/13 [00:00<00:00, 37.06it/s]\n","[4 / 50] Train: Loss = 0.13835, Accuracy = 95.39%: 100%|██████████| 572/572 [00:12<00:00, 45.75it/s]\n","[4 / 50]   Val: Loss = 0.17444, Accuracy = 94.67%: 100%|██████████| 13/13 [00:00<00:00, 37.67it/s]\n","[5 / 50] Train: Loss = 0.10749, Accuracy = 96.39%: 100%|██████████| 572/572 [00:12<00:00, 46.06it/s]\n","[5 / 50]   Val: Loss = 0.16311, Accuracy = 95.06%: 100%|██████████| 13/13 [00:00<00:00, 38.12it/s]\n","[6 / 50] Train: Loss = 0.08559, Accuracy = 97.12%: 100%|██████████| 572/572 [00:12<00:00, 46.47it/s]\n","[6 / 50]   Val: Loss = 0.16036, Accuracy = 95.26%: 100%|██████████| 13/13 [00:00<00:00, 37.13it/s]\n","[7 / 50] Train: Loss = 0.06873, Accuracy = 97.69%: 100%|██████████| 572/572 [00:12<00:00, 46.44it/s]\n","[7 / 50]   Val: Loss = 0.16518, Accuracy = 95.37%: 100%|██████████| 13/13 [00:00<00:00, 38.10it/s]\n","[8 / 50] Train: Loss = 0.05560, Accuracy = 98.13%: 100%|██████████| 572/572 [00:12<00:00, 46.38it/s]\n","[8 / 50]   Val: Loss = 0.16124, Accuracy = 95.41%: 100%|██████████| 13/13 [00:00<00:00, 36.44it/s]\n","[9 / 50] Train: Loss = 0.04543, Accuracy = 98.47%: 100%|██████████| 572/572 [00:12<00:00, 46.36it/s]\n","[9 / 50]   Val: Loss = 0.17276, Accuracy = 95.47%: 100%|██████████| 13/13 [00:00<00:00, 37.76it/s]\n","[10 / 50] Train: Loss = 0.03704, Accuracy = 98.78%: 100%|██████████| 572/572 [00:12<00:00, 46.51it/s]\n","[10 / 50]   Val: Loss = 0.17812, Accuracy = 95.40%: 100%|██████████| 13/13 [00:00<00:00, 40.88it/s]\n","[11 / 50] Train: Loss = 0.03004, Accuracy = 99.02%: 100%|██████████| 572/572 [00:12<00:00, 46.12it/s]\n","[11 / 50]   Val: Loss = 0.19134, Accuracy = 95.32%: 100%|██████████| 13/13 [00:00<00:00, 36.33it/s]\n","[12 / 50] Train: Loss = 0.02435, Accuracy = 99.23%: 100%|██████████| 572/572 [00:12<00:00, 46.45it/s]\n","[12 / 50]   Val: Loss = 0.20111, Accuracy = 95.39%: 100%|██████████| 13/13 [00:00<00:00, 38.07it/s]\n","[13 / 50] Train: Loss = 0.01962, Accuracy = 99.39%: 100%|██████████| 572/572 [00:12<00:00, 46.45it/s]\n","[13 / 50]   Val: Loss = 0.21194, Accuracy = 95.31%: 100%|██████████| 13/13 [00:00<00:00, 35.74it/s]\n","[14 / 50] Train: Loss = 0.01585, Accuracy = 99.52%: 100%|██████████| 572/572 [00:12<00:00, 46.57it/s]\n","[14 / 50]   Val: Loss = 0.22391, Accuracy = 95.28%: 100%|██████████| 13/13 [00:00<00:00, 35.88it/s]\n","[15 / 50] Train: Loss = 0.01286, Accuracy = 99.62%: 100%|██████████| 572/572 [00:12<00:00, 46.32it/s]\n","[15 / 50]   Val: Loss = 0.23566, Accuracy = 95.16%: 100%|██████████| 13/13 [00:00<00:00, 37.14it/s]\n","[16 / 50] Train: Loss = 0.01044, Accuracy = 99.70%: 100%|██████████| 572/572 [00:12<00:00, 46.95it/s]\n","[16 / 50]   Val: Loss = 0.24861, Accuracy = 95.26%: 100%|██████████| 13/13 [00:00<00:00, 37.29it/s]\n","[17 / 50] Train: Loss = 0.00882, Accuracy = 99.74%: 100%|██████████| 572/572 [00:12<00:00, 47.01it/s]\n","[17 / 50]   Val: Loss = 0.26105, Accuracy = 95.17%: 100%|██████████| 13/13 [00:00<00:00, 38.84it/s]\n","[18 / 50] Train: Loss = 0.00760, Accuracy = 99.78%: 100%|██████████| 572/572 [00:12<00:00, 47.35it/s]\n","[18 / 50]   Val: Loss = 0.26816, Accuracy = 95.22%: 100%|██████████| 13/13 [00:00<00:00, 39.54it/s]\n","[19 / 50] Train: Loss = 0.00681, Accuracy = 99.80%: 100%|██████████| 572/572 [00:12<00:00, 47.07it/s]\n","[19 / 50]   Val: Loss = 0.28428, Accuracy = 95.20%: 100%|██████████| 13/13 [00:00<00:00, 39.05it/s]\n","[20 / 50] Train: Loss = 0.00621, Accuracy = 99.81%: 100%|██████████| 572/572 [00:11<00:00, 47.76it/s]\n","[20 / 50]   Val: Loss = 0.29100, Accuracy = 95.12%: 100%|██████████| 13/13 [00:00<00:00, 39.99it/s]\n","[21 / 50] Train: Loss = 0.00580, Accuracy = 99.82%: 100%|██████████| 572/572 [00:11<00:00, 47.68it/s]\n","[21 / 50]   Val: Loss = 0.30493, Accuracy = 95.16%: 100%|██████████| 13/13 [00:00<00:00, 38.44it/s]\n","[22 / 50] Train: Loss = 0.00564, Accuracy = 99.82%: 100%|██████████| 572/572 [00:12<00:00, 47.39it/s]\n","[22 / 50]   Val: Loss = 0.30436, Accuracy = 95.16%: 100%|██████████| 13/13 [00:00<00:00, 40.23it/s]\n","[23 / 50] Train: Loss = 0.00552, Accuracy = 99.82%: 100%|██████████| 572/572 [00:12<00:00, 47.27it/s]\n","[23 / 50]   Val: Loss = 0.31416, Accuracy = 95.17%: 100%|██████████| 13/13 [00:00<00:00, 38.02it/s]\n","[24 / 50] Train: Loss = 0.00600, Accuracy = 99.80%: 100%|██████████| 572/572 [00:11<00:00, 47.81it/s]\n","[24 / 50]   Val: Loss = 0.31978, Accuracy = 95.14%: 100%|██████████| 13/13 [00:00<00:00, 38.23it/s]\n","[25 / 50] Train: Loss = 0.00527, Accuracy = 99.82%: 100%|██████████| 572/572 [00:11<00:00, 47.72it/s]\n","[25 / 50]   Val: Loss = 0.32318, Accuracy = 95.18%: 100%|██████████| 13/13 [00:00<00:00, 37.63it/s]\n","[26 / 50] Train: Loss = 0.00466, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 47.33it/s]\n","[26 / 50]   Val: Loss = 0.32922, Accuracy = 95.16%: 100%|██████████| 13/13 [00:00<00:00, 37.19it/s]\n","[27 / 50] Train: Loss = 0.00453, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 47.27it/s]\n","[27 / 50]   Val: Loss = 0.32741, Accuracy = 95.16%: 100%|██████████| 13/13 [00:00<00:00, 38.87it/s]\n","[28 / 50] Train: Loss = 0.00507, Accuracy = 99.82%: 100%|██████████| 572/572 [00:12<00:00, 47.64it/s]\n","[28 / 50]   Val: Loss = 0.33267, Accuracy = 95.12%: 100%|██████████| 13/13 [00:00<00:00, 37.68it/s]\n","[29 / 50] Train: Loss = 0.00563, Accuracy = 99.80%: 100%|██████████| 572/572 [00:12<00:00, 47.34it/s]\n","[29 / 50]   Val: Loss = 0.33756, Accuracy = 95.20%: 100%|██████████| 13/13 [00:00<00:00, 38.76it/s]\n","[30 / 50] Train: Loss = 0.00466, Accuracy = 99.83%: 100%|██████████| 572/572 [00:12<00:00, 47.09it/s]\n","[30 / 50]   Val: Loss = 0.33476, Accuracy = 95.23%: 100%|██████████| 13/13 [00:00<00:00, 39.89it/s]\n","[31 / 50] Train: Loss = 0.00417, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 47.21it/s]\n","[31 / 50]   Val: Loss = 0.34060, Accuracy = 95.17%: 100%|██████████| 13/13 [00:00<00:00, 39.01it/s]\n","[32 / 50] Train: Loss = 0.00439, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 47.25it/s]\n","[32 / 50]   Val: Loss = 0.35183, Accuracy = 95.15%: 100%|██████████| 13/13 [00:00<00:00, 38.69it/s]\n","[33 / 50] Train: Loss = 0.00486, Accuracy = 99.82%: 100%|██████████| 572/572 [00:12<00:00, 47.40it/s]\n","[33 / 50]   Val: Loss = 0.34605, Accuracy = 95.23%: 100%|██████████| 13/13 [00:00<00:00, 37.72it/s]\n","[34 / 50] Train: Loss = 0.00484, Accuracy = 99.82%: 100%|██████████| 572/572 [00:12<00:00, 46.75it/s]\n","[34 / 50]   Val: Loss = 0.34831, Accuracy = 95.13%: 100%|██████████| 13/13 [00:00<00:00, 40.04it/s]\n","[35 / 50] Train: Loss = 0.00474, Accuracy = 99.83%: 100%|██████████| 572/572 [00:12<00:00, 46.90it/s]\n","[35 / 50]   Val: Loss = 0.34761, Accuracy = 95.22%: 100%|██████████| 13/13 [00:00<00:00, 38.18it/s]\n","[36 / 50] Train: Loss = 0.00405, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 46.57it/s]\n","[36 / 50]   Val: Loss = 0.35466, Accuracy = 95.27%: 100%|██████████| 13/13 [00:00<00:00, 39.73it/s]\n","[37 / 50] Train: Loss = 0.00398, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 46.93it/s]\n","[37 / 50]   Val: Loss = 0.35142, Accuracy = 95.21%: 100%|██████████| 13/13 [00:00<00:00, 41.02it/s]\n","[38 / 50] Train: Loss = 0.00404, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 47.17it/s]\n","[38 / 50]   Val: Loss = 0.35374, Accuracy = 95.18%: 100%|██████████| 13/13 [00:00<00:00, 36.55it/s]\n","[39 / 50] Train: Loss = 0.00417, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 46.62it/s]\n","[39 / 50]   Val: Loss = 0.36104, Accuracy = 95.20%: 100%|██████████| 13/13 [00:00<00:00, 40.91it/s]\n","[40 / 50] Train: Loss = 0.00513, Accuracy = 99.81%: 100%|██████████| 572/572 [00:12<00:00, 46.47it/s]\n","[40 / 50]   Val: Loss = 0.35162, Accuracy = 95.08%: 100%|██████████| 13/13 [00:00<00:00, 39.53it/s]\n","[41 / 50] Train: Loss = 0.00458, Accuracy = 99.83%: 100%|██████████| 572/572 [00:12<00:00, 46.75it/s]\n","[41 / 50]   Val: Loss = 0.35204, Accuracy = 95.13%: 100%|██████████| 13/13 [00:00<00:00, 37.58it/s]\n","[42 / 50] Train: Loss = 0.00402, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 46.87it/s]\n","[42 / 50]   Val: Loss = 0.35634, Accuracy = 95.19%: 100%|██████████| 13/13 [00:00<00:00, 40.89it/s]\n","[43 / 50] Train: Loss = 0.00407, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 47.03it/s]\n","[43 / 50]   Val: Loss = 0.36478, Accuracy = 95.21%: 100%|██████████| 13/13 [00:00<00:00, 39.38it/s]\n","[44 / 50] Train: Loss = 0.00384, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 46.71it/s]\n","[44 / 50]   Val: Loss = 0.36151, Accuracy = 95.19%: 100%|██████████| 13/13 [00:00<00:00, 38.09it/s]\n","[45 / 50] Train: Loss = 0.00380, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 46.92it/s]\n","[45 / 50]   Val: Loss = 0.35469, Accuracy = 95.22%: 100%|██████████| 13/13 [00:00<00:00, 38.11it/s]\n","[46 / 50] Train: Loss = 0.00379, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 46.49it/s]\n","[46 / 50]   Val: Loss = 0.36509, Accuracy = 95.23%: 100%|██████████| 13/13 [00:00<00:00, 38.36it/s]\n","[47 / 50] Train: Loss = 0.00434, Accuracy = 99.83%: 100%|██████████| 572/572 [00:12<00:00, 46.44it/s]\n","[47 / 50]   Val: Loss = 0.36696, Accuracy = 95.07%: 100%|██████████| 13/13 [00:00<00:00, 37.43it/s]\n","[48 / 50] Train: Loss = 0.00568, Accuracy = 99.79%: 100%|██████████| 572/572 [00:12<00:00, 46.63it/s]\n","[48 / 50]   Val: Loss = 0.35433, Accuracy = 95.10%: 100%|██████████| 13/13 [00:00<00:00, 38.72it/s]\n","[49 / 50] Train: Loss = 0.00400, Accuracy = 99.84%: 100%|██████████| 572/572 [00:12<00:00, 46.34it/s]\n","[49 / 50]   Val: Loss = 0.35639, Accuracy = 95.20%: 100%|██████████| 13/13 [00:00<00:00, 39.37it/s]\n","[50 / 50] Train: Loss = 0.00364, Accuracy = 99.85%: 100%|██████████| 572/572 [00:12<00:00, 46.70it/s]\n","[50 / 50]   Val: Loss = 0.35751, Accuracy = 95.21%: 100%|██████████| 13/13 [00:00<00:00, 39.74it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"m0qGetIhfUE5"},"source":["### Masking\n","\n","**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n","\n","У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."]},{"cell_type":"markdown","metadata":{"id":"nAfV2dEOfHo5"},"source":["**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98wr38_rw55D","executionInfo":{"status":"ok","timestamp":1633355776421,"user_tz":-180,"elapsed":393,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"cd5b9aa2-17ab-4c3b-e918-7c69b0681de6"},"source":["loss, accuracy = do_epoch(model, criterion, (X_test, y_test), 512, None, '')"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["      Loss = 0.35551, Accuracy = 95.34%: 100%|██████████| 28/28 [00:00<00:00, 41.89it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"PXUTSFaEHbDG"},"source":["### Bidirectional LSTM\n","\n","Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n","\n","![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n","*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n","\n","**Задание** Добавьте Bidirectional LSTM."]},{"cell_type":"markdown","metadata":{"id":"ZTXmYGD_ANhm"},"source":["### Предобученные эмбеддинги\n","\n","Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n","\n","Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZpY_Q1xZ18h","executionInfo":{"status":"ok","timestamp":1633355891335,"user_tz":-180,"elapsed":114918,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"3243620d-e516-48c6-b8d7-31e2774b8377"},"source":["import gensim.downloader as api\n","\n","w2v_model = api.load('glove-wiki-gigaword-100')"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 128.1/128.1MB downloaded\n"]}]},{"cell_type":"markdown","metadata":{"id":"KYogOoKlgtcf"},"source":["Построим подматрицу для слов из нашей тренировочной выборки:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsCstxiO03oT","executionInfo":{"status":"ok","timestamp":1633355891339,"user_tz":-180,"elapsed":14,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"a041b314-ec48-40e5-bbf6-51da0fc6fa22"},"source":["known_count = 0\n","embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n","for word, ind in word2ind.items():\n","    word = word.lower()\n","    if word in w2v_model.vocab:\n","        embeddings[ind] = w2v_model.get_vector(word)\n","        known_count += 1\n","        \n","print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Know 38736 out of 45441 word embeddings\n"]}]},{"cell_type":"markdown","metadata":{"id":"HcG7i-R8hbY3"},"source":["**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."]},{"cell_type":"code","metadata":{"id":"fnkea4B8isni","executionInfo":{"status":"ok","timestamp":1633355891339,"user_tz":-180,"elapsed":8,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["embeddings = embeddings.astype('float32')"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"0N48iBaKisni","executionInfo":{"status":"ok","timestamp":1633355891340,"user_tz":-180,"elapsed":8,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["embeddings = torch.FloatTensor(embeddings)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"LxaRBpQd0pat","executionInfo":{"status":"ok","timestamp":1633355891340,"user_tz":-180,"elapsed":8,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["class LSTMTaggerWithPretrainedEmbs(nn.Module):\n","    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n","        super().__init__()\n","        vocabulary_size, word_emb_dim = embeddings.shape\n","        self.word_embeddings = nn.Embedding(vocabulary_size, word_emb_dim).from_pretrained(embeddings, freeze=False)\n","        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n","        self.hidden2tag = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n","\n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence)\n","        return self.forward_after_embeddings(embeds)\n","\n","    def forward_after_embeddings(self, embeds):\n","        lstm_out, _ = self.lstm(embeds)\n","        tag_space = self.hidden2tag(lstm_out)\n","        return tag_space"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBtI6BDE-Fc7","executionInfo":{"status":"ok","timestamp":1633355949205,"user_tz":-180,"elapsed":57873,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"6d124f97-5e5c-47d9-ca14-3a1b006b548b"},"source":["model = LSTMTaggerWithPretrainedEmbs(\n","    embeddings=embeddings,\n","    tagset_size=len(tag2ind)\n",").cuda()\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters())\n","\n","fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=5,\n","    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["[1 / 5] Train: Loss = 0.39785, Accuracy = 88.80%: 100%|██████████| 572/572 [00:11<00:00, 49.75it/s]\n","[1 / 5]   Val: Loss = 0.11952, Accuracy = 96.52%: 100%|██████████| 13/13 [00:00<00:00, 45.05it/s]\n","[2 / 5] Train: Loss = 0.07183, Accuracy = 97.78%: 100%|██████████| 572/572 [00:11<00:00, 50.66it/s]\n","[2 / 5]   Val: Loss = 0.09173, Accuracy = 97.18%: 100%|██████████| 13/13 [00:00<00:00, 48.17it/s]\n","[3 / 5] Train: Loss = 0.04587, Accuracy = 98.54%: 100%|██████████| 572/572 [00:11<00:00, 50.94it/s]\n","[3 / 5]   Val: Loss = 0.08646, Accuracy = 97.30%: 100%|██████████| 13/13 [00:00<00:00, 49.04it/s]\n","[4 / 5] Train: Loss = 0.03343, Accuracy = 98.93%: 100%|██████████| 572/572 [00:11<00:00, 50.87it/s]\n","[4 / 5]   Val: Loss = 0.09434, Accuracy = 97.29%: 100%|██████████| 13/13 [00:00<00:00, 49.73it/s]\n","[5 / 5] Train: Loss = 0.02567, Accuracy = 99.18%: 100%|██████████| 572/572 [00:11<00:00, 51.33it/s]\n","[5 / 5]   Val: Loss = 0.09926, Accuracy = 97.26%: 100%|██████████| 13/13 [00:00<00:00, 50.38it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"2Ne_8f24h8kg"},"source":["**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n","\n","Добейтесь качества лучше прошлых моделей."]},{"cell_type":"code","metadata":{"id":"OfkbEG-jisnj","executionInfo":{"status":"ok","timestamp":1633355949475,"user_tz":-180,"elapsed":293,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["def get_word_embed(word):\n","    if (word in word2ind):\n","        return model.word_embeddings.weight[word2ind[word]].cpu().detach().numpy()\n","    elif (word in w2v_model.vocab):\n","        return model.word_embeddings.weight[0].cpu().detach().numpy()\n","        #return w2v_model.get_vector(word)\n","    else:\n","        return model.word_embeddings.weight[0].cpu().detach().numpy()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZELJZ7p3isnj","executionInfo":{"status":"ok","timestamp":1633355949477,"user_tz":-180,"elapsed":11,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["def convert_data_embed(data, word2ind, tag2ind):\n","    X = [[get_word_embed(word) for word, _ in sample] for sample in data]\n","    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n","    \n","    \n","    return X, y\n","\n","def iterate_batches_embed(data, batch_size):\n","    embed_dim = 100\n","    X, y = data\n","    n_samples = len(X)\n","\n","    indices = np.arange(n_samples)\n","    np.random.shuffle(indices)\n","    \n","    for start in range(0, n_samples, batch_size):\n","        end = min(start + batch_size, n_samples)\n","        \n","        batch_indices = indices[start:end]\n","        \n","        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n","        X_batch = np.zeros((max_sent_len, len(batch_indices), embed_dim))\n","        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n","        mask = np.zeros((max_sent_len, len(batch_indices)))\n","        \n","        for batch_ind, sample_ind in enumerate(batch_indices):\n","            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n","            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n","            mask[:len(X[sample_ind]), batch_ind] = 1\n","        yield X_batch, y_batch, mask"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xUWf7Zeisnk","executionInfo":{"status":"ok","timestamp":1633355964957,"user_tz":-180,"elapsed":15490,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["X_test_embed, y_test_embed = convert_data_embed(test_data, word2ind, tag2ind)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJUOf5F9isnk","executionInfo":{"status":"ok","timestamp":1633355964958,"user_tz":-180,"elapsed":38,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}}},"source":["def eval(data, batch_size):\n","    epoch_loss = 0\n","    correct_count = 0\n","    sum_count = 0\n","    batches_count = 0\n","\n","    for i, (X_batch, y_batch, mask) in enumerate(iterate_batches_embed(data, batch_size)):\n","        X_batch, y_batch, mask = FloatTensor(X_batch), LongTensor(y_batch), LongTensor(mask)\n","        logits = model.forward_after_embeddings(X_batch)\n","\n","        loss = criterion(torch.movedim(logits, 0, -1), y_batch.movedim(0, -1))\n","\n","        epoch_loss += loss.item()\n","        cur_correct_count = torch.sum(torch.mul(torch.argmax(logits, dim=-1) == y_batch, mask)).item()\n","        cur_sum_count = torch.sum(mask).item()\n","\n","        correct_count += cur_correct_count\n","        sum_count += cur_sum_count\n","        batches_count += 1\n","    print(\"Loss: \", epoch_loss / batches_count, \"Accuracy: \", correct_count / sum_count)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAqqMKd6isnk","executionInfo":{"status":"ok","timestamp":1633355966272,"user_tz":-180,"elapsed":1350,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"f3c8a8d4-e463-476f-b949-9b888161592b"},"source":["eval((X_test_embed, y_test_embed), 512)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss:  0.09905395683433328 Accuracy:  0.9727234231535895\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SfyIO3QTisnk","executionInfo":{"status":"ok","timestamp":1633355966983,"user_tz":-180,"elapsed":723,"user":{"displayName":"Кирилл Беляков","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03377521928356666185"}},"outputId":"f55dfb09-d3a0-461d-84dd-b63bf8986a14"},"source":["# not using words out of train embeddings\n","loss, accuracy = do_epoch(model, criterion, (X_test, y_test), 512, None, '')"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["      Loss = 0.09892, Accuracy = 97.28%: 100%|██████████| 28/28 [00:00<00:00, 39.61it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"1V3pFjjZisnk"},"source":[""],"execution_count":null,"outputs":[]}]}